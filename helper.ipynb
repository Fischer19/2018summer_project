{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  93.2780,   94.1870,   61.0000],\n",
      "        [  94.1870,   95.0960,   68.0000],\n",
      "        [  95.0960,   96.0050,   65.0000],\n",
      "        [  96.0050,   96.9150,   66.0000],\n",
      "        [  96.9170,   97.2200,   63.0000],\n",
      "        [  97.2200,   97.5230,   63.0000],\n",
      "        [  97.5230,   97.8260,   63.0000],\n",
      "        [  97.8260,   98.4320,   58.0000],\n",
      "        [  98.4320,   98.7350,   56.0000],\n",
      "        [  98.7350,   99.3410,   54.0000],\n",
      "        [ 115.0430,  115.3460,   61.0000],\n",
      "        [ 115.3460,  115.6490,   61.0000],\n",
      "        [ 115.6490,  115.9520,   61.0000],\n",
      "        [ 115.9520,  116.5590,   56.0000],\n",
      "        [ 116.5590,  116.8620,   58.0000],\n",
      "        [ 116.8620,  117.4680,   56.0000],\n",
      "        [ 117.4680,  117.7710,   54.0000],\n",
      "        [ 117.7710,  118.6800,   49.0000]], dtype=torch.float64)\n",
      "tensor([ 0,  0,  1,  1,  0,  0,  0,  1,  1,  1,  0,  0,  0,  0,\n",
      "         1,  1,  1,  1])\n"
     ]
    }
   ],
   "source": [
    "# prepare shuffled balanced data\n",
    "with open(\"/home/yiqin/2018summer_project/balanced_data_small.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "new_data = []\n",
    "for i in range(len(train_X)):\n",
    "    new_data.append((train_X[i], train_Y[i]))\n",
    "shuffle(new_data)\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for i in range(len(new_data)):\n",
    "    train_X.append(new_data[i][0])\n",
    "    train_Y.append(new_data[i][1])\n",
    "print(train_X[0])\n",
    "print(train_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19666\n",
      "19666\n",
      "19666\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "dic[\"X\"] = train_X\n",
    "dic[\"Y\"] = train_Y\n",
    "input_dim2 = []\n",
    "for i in range(len(train_X)):\n",
    "    input_dim2.append(torch.cat([train_X[i][:,1].unsqueeze(1) - train_X[i][:,0].unsqueeze(1),\n",
    "                                 train_X[i][:,2].unsqueeze(1)], dim = 1))\n",
    "dic[\"X2\"] = input_dim2\n",
    "f = open(\"balanced_data_shuffle.pkl\", \"wb\")\n",
    "pickle.dump(dic, f)\n",
    "f.close()\n",
    "\n",
    "print(len(dic[\"X2\"]))\n",
    "print(len(dic[\"X\"]))\n",
    "print(len(dic[\"Y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1]\n",
      "[2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 4 2 3 3 3 4 2 3 3 3 3 3 3 3 3 3 3 4 2 3\n",
      " 3 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 3 4 2 3 3 3\n",
      " 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3\n",
      " 4 2 3 3 3 3 3 3 3 3 3 4 0 2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 2 3 3\n",
      " 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 0 2 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3\n",
      " 4 2 3 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 4 2 3 3\n",
      " 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 0 2 3 3 3 3 3 3\n",
      " 3 4 2 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 0 2 3\n",
      " 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3\n",
      " 3 4 0 2 3 3 3 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 4]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "# load data from file\n",
    "with open(\"/home/yiqin/2018summer_project/DeepMusic/pitch_data.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "    #time_X = dic[\"time\"]\n",
    "    \n",
    "\"\"\"for i in range(train_Y.shape[0]):\n",
    "    train_Y[i] = torch.from_numpy((train_Y[i] == 4).astype(int)).float()\n",
    "    \"\"\"\n",
    "    \n",
    "with open(\"/home/yiqin/2018summer_project/balanced_target.pkl\", \"rb\") as f:\n",
    "    balanced_train_Y = np.array(pickle.load(f))\n",
    "print(balanced_train_Y[50].reshape(-1))\n",
    "print(train_Y[50].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_factorize(target, balanced_target, input_data):\n",
    "    train_X = input_data\n",
    "    train_Y = target\n",
    "    new_label = []\n",
    "    new_input = []\n",
    "    for i, target in enumerate(train_Y):\n",
    "        two_list = []\n",
    "        four_list = []\n",
    "        # in case of bad data\n",
    "        target[-1] = 4\n",
    "        loc = 0\n",
    "        two_list.append(0)\n",
    "        for label in target:\n",
    "            if int(label[0]) == 4:\n",
    "                two_list.append(loc + 1)\n",
    "                four_list.append(loc)\n",
    "            loc = loc + 1\n",
    "        two_list.pop()\n",
    "        prev = 0\n",
    "        for j in range(2, len(four_list), 3):\n",
    "            new_label.append(torch.from_numpy(balanced_target[i][prev:four_list[j]+1].squeeze()))\n",
    "            new_input.append(torch.from_numpy(train_X[i][prev:four_list[j]+1]))\n",
    "            prev = four_list[j]+1\n",
    "            end = j\n",
    "        if j != len(four_list) - 1:\n",
    "            new_label.append(torch.from_numpy(balanced_target[i][prev:].squeeze()))\n",
    "            new_input.append(torch.from_numpy(train_X[i][prev:]))\n",
    "    return new_label, new_input\n",
    "\n",
    "#new_label, new_input = target_factorize(target=train_Y, balanced_target=balanced_train_Y, input_data=train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dic = {}\n",
    "dic[\"X\"] = new_input\n",
    "dic[\"Y\"] = new_label\n",
    "f = open(\"balanced_data_small.pkl\", \"wb\")\n",
    "pickle.dump(dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim2 = []\n",
    "for i in range(len(new_input)):\n",
    "    input_dim2.append(torch.cat([new_input[i][:,1].unsqueeze(1) - new_input[i][:,0].unsqueeze(1),\n",
    "                                 new_input[i][:,2].unsqueeze(1)], dim = 1))\n",
    "dic[\"X2\"] = input_dim2\n",
    "f = open(\"balanced_data_small.pkl\", \"wb\")\n",
    "pickle.dump(dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"def input_transform(train_x, time_x, i):\n",
    "    output = torch.from_numpy(np.array([train_x[i], time_x[i]]))\n",
    "    return output.transpose(1, 0).to(device)\n",
    "\"\"\"\n",
    "\n",
    "def input_transform(train_x, i):\n",
    "    output = torch.Tensor([train_x[i][:,1] - train_x[i][:,0], train_x[i][:,2]])\n",
    "    return output.squeeze(0).transpose(1,0).to(device)\n",
    "    \n",
    "    \n",
    "def input_factorize(train_x):\n",
    "    output = []\n",
    "    for i in range(len(train_x)):\n",
    "        for item in np.array_split(train_x[i], train_x[i].shape[0] / 30):\n",
    "            output.append(item)\n",
    "    return output\n",
    "\n",
    "\n",
    "def target_factorize(train_y):\n",
    "    output = []\n",
    "    for i in range(len(train_y)):\n",
    "        for item in np.array_split(train_y[i], train_y[i].shape[0] / 30):\n",
    "            output.append(torch.Tensor(item).squeeze())\n",
    "    return output\n",
    "\n",
    "def target_transform(train_y):\n",
    "    output = torch.zeros((1, 2))\n",
    "    output[0, int(train_y)] = 1\n",
    "    return output.unsqueeze(1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding the data tensor:\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with open(\"/home/yiqin/2018summer_project/balanced_data_small.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X2\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "\n",
    "padding_data = []\n",
    "padding_label = []\n",
    "maximum = 0\n",
    "for i in range(len(train_X)):\n",
    "    if train_X[i].shape[0] < 3:\n",
    "        continue\n",
    "    padding_data.append(F.pad(train_X[i], (0,0,0,70-train_X[i].shape[0]), value = 0))\n",
    "    padding_label.append(F.pad(train_Y[i], (0, 70-train_X[i].shape[0]), value = 2))\n",
    "    \n",
    "dic = {}\n",
    "dic[\"X\"] =  padding_data\n",
    "dic[\"Y\"] = padding_label\n",
    "\n",
    "f = open(\"balanced_data_padding.pkl\", \"wb\")\n",
    "pickle.dump(dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19626, 70, 2])\n"
     ]
    }
   ],
   "source": [
    "data = torch.stack(padding_data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a23b22effdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'util'"
     ]
    }
   ],
   "source": [
    "dataset = torch.util.data.Dataset(padding_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/yiqin/2018summer_project/balanced_data_small.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    smooth_train_X = dic[\"X2\"]\n",
    "    \n",
    "with open(\"/home/yiqin/2018summer_project/smooth_data.pkl\", \"rb\") as f:\n",
    "    smooth_train_Y = pickle.load(f)\n",
    "smooth_train_Y, _ = target_factorize(train_Y, smooth_train_Y, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5000,  0.2500,  0.1250,  0.0625,  0.0312,  0.0312,  0.0312,\n",
      "         0.0625,  0.1250,  0.2500,  0.5000,  1.0000,  0.5000,  0.2500,\n",
      "         0.1250,  0.0625,  0.0312,  0.0312,  0.0312,  0.0625,  0.1250,\n",
      "         0.2500,  0.5000,  1.0000,  0.5000,  0.2500,  0.1250,  0.0625,\n",
      "         0.0312,  0.0312,  0.0625,  0.1250,  0.2500,  0.5000,  1.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14])\n",
      "torch.Size([14, 2])\n"
     ]
    }
   ],
   "source": [
    "print(smooth_train_Y[1000].shape)\n",
    "print(smooth_train_X[1000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/home/yiqin/2018summer_project/smooth_data.pkl\", \"wb\")\n",
    "dic = {}\n",
    "dic[\"X\"] = smooth_train_X\n",
    "dic[\"Y\"] = smooth_train_Y\n",
    "pickle.dump(dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
